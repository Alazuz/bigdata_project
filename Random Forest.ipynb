{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0618ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import yfinance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('data\\df.csv',sep='|')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "#plt.figure(figsize=(12, 6))\n",
    "#plt.plot(ts)\n",
    "#plt.title('Prix journaliers du S&P500')\n",
    "#plt.show()\n",
    "\n",
    "DXY = yfinance.download('DX-Y.NYB', start='1999-01-04', end='2025-09-19')\n",
    "DXY = DXY.reset_index()[['Date','Close']]\n",
    "DXY.columns = ['date','DXY']\n",
    "data=data.merge(DXY, on='date', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "class SP500RandomForestRegressor:\n",
    "    \"\"\"\n",
    "    Random Forest pour prédire le PRIX FUTUR du S&P 500\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.feature_names = []\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def load_and_prepare_data(self, file_path, target_column='close', forecast_horizon=1):\n",
    "        \"\"\"\n",
    "        Charge et prépare les données pour prédire le prix futur\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        file_path : str\n",
    "            Chemin vers le fichier Excel\n",
    "        target_column : str\n",
    "            Colonne contenant les prix du S&P 500\n",
    "        forecast_horizon : int\n",
    "            Nombre de jours à l'avance à prédire (1 = demain, 5 = dans 5 jours)\n",
    "        \"\"\"\n",
    "        # Charger les données\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Gérer l'index temporel\n",
    "        date_cols = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "        if date_cols:\n",
    "            df[date_cols[0]] = pd.to_datetime(df[date_cols[0]])\n",
    "            df.set_index(date_cols[0], inplace=True)\n",
    "            df = df.sort_index()\n",
    "        \n",
    "        self.data = df.copy()\n",
    "        \n",
    "        # Créer les features\n",
    "        df = self._create_temporal_features(df, target_column)\n",
    "        \n",
    "        # IMPORTANT : Créer la variable cible = PRIX FUTUR\n",
    "        df['target'] = df[target_column].shift(-forecast_horizon)\n",
    "        \n",
    "        print(f\"Target créée: Prix dans {forecast_horizon} jour(s)\")\n",
    "        \n",
    "        # Sélectionner les features (exclure le prix actuel pour éviter le data leakage)\n",
    "        exclude_cols = [target_column, 'target', 'Open', 'High', 'Low', 'close']\n",
    "        feature_cols = [col for col in df.columns \n",
    "                       if col not in exclude_cols \n",
    "                       and df[col].dtype in ['int64', 'float64', 'bool']]\n",
    "        \n",
    "        # Supprimer les lignes avec NaN\n",
    "        df_clean = df[feature_cols + ['target']].dropna()\n",
    "        \n",
    "        self.X = df_clean[feature_cols]\n",
    "        self.y = df_clean['target']\n",
    "        self.feature_names = feature_cols\n",
    "        \n",
    "        return self.X, self.y\n",
    "    \n",
    "    def _create_temporal_features(self, df, target_column):\n",
    "        \"\"\"\n",
    "        Crée des features à partir de l'historique des prix\n",
    "        \"\"\"\n",
    "        # 1. Lags de prix (valeurs passées)\n",
    "        for lag in [1, 2, 3, 5, 10]:\n",
    "            df[f'price_lag_{lag}'] = df[target_column].shift(lag)\n",
    "        \n",
    "        # 2. Rendements passés\n",
    "        df['return_1d'] = df[target_column].pct_change()\n",
    "        df['return_2d'] = df[target_column].pct_change(2)\n",
    "        df['return_5d'] = df[target_column].pct_change(5)\n",
    "        df['return_10d'] = df[target_column].pct_change(10)\n",
    "        \n",
    "        # 3. Moyennes mobiles\n",
    "        for window in [5, 10, 20, 50]:\n",
    "            df[f'ma_{window}'] = df[target_column].rolling(window).mean()\n",
    "            df[f'price_vs_ma_{window}'] = (df[target_column] - df[f'ma_{window}']) / df[f'ma_{window}']\n",
    "        \n",
    "        # 4. Volatilité\n",
    "        df['volatility_5d'] = df['return_1d'].rolling(5).std()\n",
    "        df['volatility_10d'] = df['return_1d'].rolling(10).std()\n",
    "        df['volatility_20d'] = df['return_1d'].rolling(20).std()\n",
    "        \n",
    "        # 5. Momentum\n",
    "        df['momentum_5d'] = df[target_column] / df[target_column].shift(5) - 1\n",
    "        df['momentum_10d'] = df[target_column] / df[target_column].shift(10) - 1\n",
    "        \n",
    "        # 6. RSI (Relative Strength Index)\n",
    "        delta = df[target_column].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "        rs = gain / loss\n",
    "        df['rsi'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # 7. Features OHLC (si disponibles)\n",
    "        if all(col in df.columns for col in ['Open', 'High', 'Low', 'close']):\n",
    "            df['daily_range'] = (df['High'] - df['Low']) / df['close']\n",
    "            df['body'] = (df['close'] - df['Open']) / df['close']\n",
    "            df['upper_shadow'] = (df['High'] - df[['Open', 'close']].max(axis=1)) / df['close']\n",
    "            df['lower_shadow'] = (df[['Open', 'close']].min(axis=1) - df['Low']) / df['close']\n",
    "        \n",
    "        # 8. Volume (si disponible)\n",
    "        if 'Volume' in df.columns:\n",
    "            df['volume_ma_20'] = df['Volume'].rolling(20).mean()\n",
    "            df['volume_ratio'] = df['Volume'] / df['volume_ma_20']\n",
    "        \n",
    "        # 10. VIX ou autres variables (si disponibles)\n",
    "        for col in df.columns:\n",
    "            if col not in [target_column, 'Open', 'High', 'Low', 'close', 'Volume']:\n",
    "                if df[col].dtype in ['float64', 'int64']:\n",
    "                    df[f'{col}_lag_1'] = df[col].shift(1)\n",
    "                    df[f'{col}_change'] = df[col].diff()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def fit_random_forest(self, n_estimators=100, max_depth=15, min_samples_split=20):\n",
    "        \"\"\"\n",
    "        Entraîne le modèle Random Forest\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Données non préparées. Utilisez load_and_prepare_data() d'abord.\")\n",
    "        \n",
    "        print(f\"\\n🌲 Entraînement Random Forest Regressor...\")\n",
    "        print(f\"  - Nombre d'arbres: {n_estimators}\")\n",
    "        print(f\"  - Profondeur max: {max_depth}\")\n",
    "        print(f\"  - Min samples split: {min_samples_split}\")\n",
    "        \n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=10,\n",
    "            max_features='sqrt',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        self.model.fit(self.X, self.y)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        print(f\"Modèle entraîné avec succès!\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def optimize_hyperparameters(self):\n",
    "        \"\"\"\n",
    "        Optimise les hyperparamètres avec validation croisée temporelle\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Optimisation des hyperparamètres (cela peut prendre du temps)...\")\n",
    "        \n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [10, 15, 20, None],\n",
    "            'min_samples_split': [20, 50, 100],\n",
    "            'min_samples_leaf': [10, 20],\n",
    "            'max_features': ['sqrt', 0.3, 0.5]\n",
    "        }\n",
    "        \n",
    "        # Validation croisée temporelle (important pour séries temporelles)\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "            param_grid,\n",
    "            cv=tscv,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(self.X, self.y)\n",
    "        \n",
    "        self.model = grid_search.best_estimator_\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        print(f\"Meilleurs paramètres: {grid_search.best_params_}\")\n",
    "        print(f\"Meilleur score MSE: {-grid_search.best_score_:.2f}\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def validate_model(self, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Valide le modèle avec un split temporel\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Modèle non entraîné.\")\n",
    "        \n",
    "        # Split temporel : les dernières données pour le test\n",
    "        split_idx = int(len(self.X) * (1 - test_size))\n",
    "        \n",
    "        X_train, X_test = self.X.iloc[:split_idx], self.X.iloc[split_idx:]\n",
    "        y_train, y_test = self.y.iloc[:split_idx], self.y.iloc[split_idx:]\n",
    "        \n",
    "        # Prédictions\n",
    "        y_pred_train = self.model.predict(X_train)\n",
    "        y_pred_test = self.model.predict(X_test)\n",
    "        \n",
    "        # Métriques\n",
    "        print(f\"VALIDATION DU MODÈLE\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        print(f\"DONNÉES D'ENTRAÎNEMENT ({len(X_train)} obs)\")\n",
    "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        print(f\"  MAE:  {train_mae:.2f} points\")\n",
    "        print(f\"  RMSE: {train_rmse:.2f} points\")\n",
    "        print(f\"  R²:   {train_r2:.4f}\")\n",
    "        \n",
    "        print(f\"DONNÉES DE TEST ({len(X_test)} obs)\")\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        test_mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "        \n",
    "        print(f\"  MAE:  {test_mae:.2f} points\")\n",
    "        print(f\"  RMSE: {test_rmse:.2f} points\")\n",
    "        print(f\"  R²:   {test_r2:.4f}\")\n",
    "        print(f\"  MAPE: {test_mape:.2f}%\")\n",
    "        \n",
    "        # Graphiques\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # 1. Prédictions vs Réel (scatter)\n",
    "        axes[0, 0].scatter(y_test, y_pred_test, alpha=0.5)\n",
    "        axes[0, 0].plot([y_test.min(), y_test.max()], \n",
    "                       [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "        axes[0, 0].set_xlabel('Prix Réel')\n",
    "        axes[0, 0].set_ylabel('Prix Prédit')\n",
    "        axes[0, 0].set_title('Prédictions vs Réalité (Test)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Série temporelle des prédictions\n",
    "        recent_test = y_test.tail(50)\n",
    "        recent_pred = pd.Series(y_pred_test, index=y_test.index).tail(50)\n",
    "        axes[0, 1].plot(recent_test.index, recent_test, label='Réel', linewidth=2)\n",
    "        axes[0, 1].plot(recent_pred.index, recent_pred, label='Prédit', \n",
    "                       linestyle='--', linewidth=2)\n",
    "        axes[0, 1].set_title('50 dernières prédictions')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 3. Erreurs de prédiction\n",
    "        errors = y_test - y_pred_test\n",
    "        axes[1, 0].hist(errors, bins=30, edgecolor='black')\n",
    "        axes[1, 0].set_xlabel('Erreur de prédiction (points)')\n",
    "        axes[1, 0].set_ylabel('Fréquence')\n",
    "        axes[1, 0].set_title(f'Distribution des erreurs (Moyenne: {errors.mean():.2f})')\n",
    "        axes[1, 0].axvline(x=0, color='red', linestyle='--')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Erreurs dans le temps\n",
    "        axes[1, 1].plot(y_test.index, errors)\n",
    "        axes[1, 1].axhline(y=0, color='red', linestyle='--')\n",
    "        axes[1, 1].set_title('Erreurs de prédiction dans le temps')\n",
    "        axes[1, 1].set_ylabel('Erreur (points)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'train_mae': train_mae, 'train_rmse': train_rmse, 'train_r2': train_r2,\n",
    "            'test_mae': test_mae, 'test_rmse': test_rmse, 'test_r2': test_r2, 'test_mape': test_mape\n",
    "        }\n",
    "    \n",
    "    def feature_importance(self, top_n=15):\n",
    "        \"\"\"\n",
    "        Analyse l'importance des features\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Modèle non entraîné.\")\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\" TOP {top_n} FEATURES LES PLUS IMPORTANTES\")\n",
    "        print(\"=\"*50)\n",
    "        for i, row in importance_df.head(top_n).iterrows():\n",
    "            print(f\"{row['feature']:30s} {row['importance']:.4f}\")\n",
    "        \n",
    "        # Graphique\n",
    "        top_features = importance_df.head(top_n)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(range(len(top_features)), top_features['importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.title(f'Top {top_n} Features - Random Forest')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def predict_future_price(self, display_last_n=10):\n",
    "        \"\"\"\n",
    "        Prédit le prix futur avec les dernières données disponibles\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Modèle non entraîné.\")\n",
    "        \n",
    "        # Utiliser les dernières observations\n",
    "        last_features = self.X.iloc[-display_last_n:]\n",
    "        predictions = self.model.predict(last_features)\n",
    "        \n",
    "        print(f\" PRÉDICTIONS DU PRIX FUTUR\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i in range(len(last_features)):\n",
    "            idx = last_features.index[i]\n",
    "            pred_price = predictions[i]\n",
    "            actual_price = self.y.loc[idx] if idx in self.y.index else None\n",
    "            \n",
    "            if actual_price is not None:\n",
    "                error = pred_price - actual_price\n",
    "                print(f\"{idx.strftime('%Y-%m-%d') if hasattr(idx, 'strftime') else idx}: \"\n",
    "                      f\"Prédit={pred_price:.2f}, Réel={actual_price:.2f}, \"\n",
    "                      f\"Erreur={error:+.2f}\")\n",
    "            else:\n",
    "                print(f\"{idx.strftime('%Y-%m-%d') if hasattr(idx, 'strftime') else idx}: \"\n",
    "                      f\"Prix prédit = {pred_price:.2f}\")\n",
    "        \n",
    "        # Dernière prédiction (la plus récente)\n",
    "        latest_prediction = predictions[-1]\n",
    "        print(f\"\\n💡 PRÉDICTION LA PLUS RÉCENTE: {latest_prediction:.2f} $\")\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# ============================================\n",
    "# EXEMPLE D'UTILISATION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"  RANDOM FOREST - PRÉDICTION DU PRIX S&P 500\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Créer le modèle\n",
    "    rf_model = SP500RandomForestRegressor()\n",
    "    \n",
    "    # Charger et préparer vos données\n",
    "    X, y = rf_model.load_and_prepare_data(\n",
    "        \"sp.xlsx\",  # ← VOTRE FICHIER\n",
    "        target_column='close',  # ← Ajuster selon votre colonne\n",
    "        forecast_horizon=1  # Prédire le prix de demain\n",
    "    )\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    rf_model.fit_random_forest(n_estimators=100, max_depth=15)\n",
    "    \n",
    "    # OU optimiser les hyperparamètres (plus lent mais meilleur)\n",
    "    # rf_model.optimize_hyperparameters()\n",
    "    \n",
    "    # Valider le modèle\n",
    "    metrics = rf_model.validate_model(test_size=0.2)\n",
    "    \n",
    "    # Analyser l'importance des features\n",
    "    importance = rf_model.feature_importance(top_n=15)\n",
    "    \n",
    "    # Faire des prédictions sur les dernières données\n",
    "    predictions = rf_model.predict_future_price(display_last_n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
